{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datahandling():\n",
    "    def __init__(self,name_dataframe):\n",
    "        self.name_dataframe = name_dataframe\n",
    "        self.columns = ['iteration','wrapper','optimal_number_of_features','score_optimal_features','scoring_type',\n",
    "                                            'cross_val_times','datapoints','params','running_time']\n",
    "        try:\n",
    "            self.current_df = pd.read_csv('results/'+name_dataframe)\n",
    "            self.highest_iteration = max(self.current_df['iteration'].values)\n",
    "        except Exception as e:\n",
    "            #print(f\"Error {e} occured\")\n",
    "            print('New dataframe will be made')\n",
    "            if not settings[\"allow_creating_new_results_df\"]:\n",
    "                if not input(\"Type YES if this is oke\") == \"YES\": \n",
    "                    raise TypeError(\"User decided to cancel process, so canceling. Program will crash bc no highest iter and df\")\n",
    "                else: #not pretty to have 2 times same else, but very tired at the moment\n",
    "                    self.current_df = pd.DataFrame(columns=self.columns)\n",
    "                    self.highest_iteration = 0\n",
    "            \n",
    "            else:\n",
    "                self.current_df = pd.DataFrame(columns=self.columns)\n",
    "                self.highest_iteration = 0\n",
    "            \n",
    "    def save_after_iter(self,final_model):\n",
    "        final_model.to_csv('results/'+self.name_dataframe,index=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_ranking(rfecv,final_columns,type_model):\n",
    "    ranking_all_features= {}\n",
    "    for i,col in enumerate([final_columns[i] for i in range(len(rfecv.support_)) if rfecv.support_[i] == True]):\n",
    "        if type_model == 'svm':\n",
    "            for rank, score in enumerate(sorted(rfecv.estimator_.coef_,reverse=True)):\n",
    "                if rfecv.estimator_.coef_[i] == score:\n",
    "                    ranking_all_features[col] = rank+1\n",
    "        elif type_model == 'rf':\n",
    "            print(col)\n",
    "            for rank, score in enumerate(sorted(rfecv.estimator_.feature_importances_,reverse=True)):\n",
    "                if rfecv.estimator_.feature_importances_[i] == score:\n",
    "                    ranking_all_features[col] = rank+1\n",
    "                    print(score)\n",
    "\n",
    "                    print(rank+1)\n",
    "#     print('summary score for selected features: ',ranking_selected)\n",
    "    for i,col in enumerate(final_columns):\n",
    "        if rfecv.support_[i] == False:\n",
    "            ranking_all_features[col] = rfecv.ranking_[i] \n",
    "\n",
    "    if len(ranking_all_features) != len(rfecv.support_):\n",
    "        print(\"Difference in len between ranking and support\")\n",
    "    return ranking_all_features\n",
    "\n",
    "def make_plot(rfecv, type_model):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.title('Recursive Feature Elimination with Cross-Validation', fontsize=18, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Number of features selected', fontsize=14, labelpad=20)\n",
    "    plt.ylabel('% Correct Classification', fontsize=14, labelpad=20)\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), [score*-1 for score in rfecv.grid_scores_], color='#303F9F', linewidth=3)\n",
    "    plt.savefig(f\"results/{type_model}_overview_feature_selection.png\")\n",
    "    \n",
    "data = Datahandling('scores_rfc_columns.csv')\n",
    "highest_iter = data.highest_iteration\n",
    "df_models_scores = data.current_df\n",
    "df_scores = pd.DataFrame(index=final_columns)\n",
    "if 'rfc' in settings['wrapper_tech'].keys():\n",
    "    t1 = time.time()\n",
    "    for type_model in settings['models'].keys():\n",
    "        t2 = time.time()\n",
    "        if 'svm' ==type_model:\n",
    "            model = SVC(**settings['models']['svm'])\n",
    "        elif 'rf' == type_model:\n",
    "            model = RandomForestClassifier(**settings['models']['rf'])\n",
    "        \n",
    "        rfecv = RFECV(estimator=model,\n",
    "                      scoring=settings[\"scoring_type\"],\n",
    "                      cv=settings['cross_val_times'],\n",
    "                     verbose=2).fit(X, y)  \n",
    "        \n",
    "        ranking_all_features = calculate_ranking(rfecv,final_columns,type_model)\n",
    "        scores = {column:{} for column in final_columns}\n",
    "        for i in range(len(final_columns)):\n",
    "            scores[final_columns[i]] = {\n",
    "                f\"selected_{type_model}\":rfecv.support_[i],\n",
    "                f\"ranking_{type_model}\":ranking_all_features[final_columns[i]]} #selected features are always 1 \n",
    "\n",
    "        summary = [{\n",
    "            'wrapper':type_model,\n",
    "            'iteration':highest_iter +1,\n",
    "            'grid_scores': rfecv.grid_scores_,\n",
    "            'scores':scores,\n",
    "            'optimal_number_of_features':rfecv.n_features_,\n",
    "            'score_optimal_features':rfecv.grid_scores_[rfecv.n_features_-1],\n",
    "            'scoring_type':settings['scoring_type'],\n",
    "            \"cross_val_times\":2,\n",
    "            \"datapoints\":settings['datapoints'],\n",
    "            'params':settings['models'][type_model],\n",
    "            'running_time':time.time() - t2,\n",
    "            'scores':scores,\n",
    "            'ranking':[ranking_all_features[col] for col in final_columns ]\n",
    "        }\n",
    "        ]\n",
    "    \n",
    "\n",
    "        df_models_scores = df_models_scores.append(summary,ignore_index=True)\n",
    "        make_plot(rfecv, type_model)\n",
    "#df_scores.to_csv(\"data/scores_rfc_columnsvvvvvvvv.csv\")\n",
    "data.save_after_iter(df_models_scores)\n",
    "#df_models_scores.to_csv(\"data/scores_rfc_models.csv\")\n",
    "print(f\"total running time: {time.time() - t1}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import winsound\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "                \"dataset\":\"data_after_cleaning_norm.csv\",\n",
    "                \"columns_dataset\": \"scores_after_multicol.csv\",\n",
    "                \"wrapper_tech\": {\n",
    "                        'rfc':{},\n",
    "                        'ga':{},\n",
    "                        'Boruta':{\n",
    "                            \"n_estimators\":'auto',\n",
    "                            \"verbose\":2\n",
    "                            },\n",
    "                        'xgboost':{}\n",
    "                },\n",
    "                \"models\":\n",
    "                    {\n",
    "                        'svm':\n",
    "                             {\n",
    "                                  'kernel':\"linear\"\n",
    "                             },\n",
    "                        'rf':\n",
    "                             {\n",
    "                                     'n_estimators':600,\n",
    "                                     'max_depth':30,\n",
    "                                     'min_samples_split':5,\n",
    "                                     'min_samples_leaf':4,\n",
    "                                     'max_features':'auto',\n",
    "                                     'bootstrap':True,\n",
    "                                     'n_jobs':-1\n",
    "                             }\n",
    "                    },\n",
    "                \"scoring_type\":'accuracy',\n",
    "                \"cross_val_times\":2,\n",
    "                \"datapoints\":50000, #fill in all if you want to use all datapoints,\n",
    "                \"allow_creating_new_results_df\":True, #only allow making new results df when True (risky to keep on true after testing)\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/' + settings[\"dataset\"])\n",
    "\n",
    "data2 = data\n",
    "data2['difference'] = data2['close_price_next_min']-data2['ETHBTC__ticker_info__close_price']\n",
    "data2['dummy_next_start_time'] = data2['difference'].apply(lambda x: 1 if x > 0 else 0) \n",
    "data2 = data2.drop(columns=['difference','close_price_next_min','last_start_time'])\n",
    "\n",
    "columns = list(data2.columns)\n",
    "columns.append(\"dummy_next_start_time\") \n",
    "final_columns = [column for column in columns if column!=\"dummy_next_start_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2[final_columns].values\n",
    "y = data2[\"dummy_next_start_time\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce dataset if needed\n",
    "if settings['datapoints'] is not 'all':\n",
    "    X = X[:settings['datapoints']]\n",
    "    y = y[:settings['datapoints']]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 50000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X),len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_svc = SVC(kernel=\"linear\")\n",
    "\n",
    "rfecv_svc = RFECV(estimator=model_svc,\n",
    "                      scoring=settings[\"scoring_type\"],\n",
    "                      min_features_to_select = 300,\n",
    "                      cv = 3,\n",
    "                      n_jobs = -1,\n",
    "                      verbose=2).fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svc_rfe_scores = list(rfecv_svc.estimator_.coef_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolommen = list(data2.columns)\n",
    "kolommen = kolommen[:343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_RFE_importance_ranking = pd.DataFrame()\n",
    "\n",
    "SVC_RFE_importance_ranking['var'] = kolommen\n",
    "SVC_RFE_importance_ranking['imp'] = svc_rfe_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVC_RFE_importance_ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVC_RFE_importance_ranking = SVC_RFE_importance_ranking.sort_values(by=['imp'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVC_RFE_importance_ranking = SVC_RFE_importance_ranking.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC_RFE_importance_ranking.to_csv(r'results/Feature_importance_ranking/SVC_RFE_Ranking2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(    n_estimators =600,\n",
    "                                       max_depth=30,\n",
    "                                       min_samples_split=5,\n",
    "                                       min_samples_leaf=4,\n",
    "                                       max_features='auto',\n",
    "                                       bootstrap=True,\n",
    "                                       n_jobs=-1)\n",
    "    \n",
    "rfecv = RFECV(estimator=model_rfc,\n",
    "                      scoring=settings[\"scoring_type\"],\n",
    "                      min_features_to_select = 300,\n",
    "                      verbose=2).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_345_rf_rfe = list(rfecv.estimator_.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolommen = list(data2.columns)\n",
    "kolommen = kolommen[:343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_RFE_importance_ranking = pd.DataFrame()\n",
    "\n",
    "\n",
    "RF_RFE_importance_ranking['var'] = kolommen\n",
    "RF_RFE_importance_ranking['imp'] = scores_345_rf_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RF_RFE_importance_ranking = RF_RFE_importance_ranking.sort_values(by=['imp'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RF_RFE_importance_ranking = RF_RFE_importance_ranking.reset_index(drop=True)\n",
    "RF_RFE_importance_ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF_RFE_importance_ranking.to_csv(r'results/Feature_importance_ranking/RE_RFE_Ranking.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br><br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br><br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br><br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br><br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samen = {}\n",
    "for i in range(len(kolommen)):\n",
    "    samen[kolommen[i]] = scores_345_rf_rfe[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "samen_reversed = sorted(samen.items(),key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samen_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('ranking_rf_rfe_345.npy', samen_reversed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_345_rf_rfe.sort(reverse=True)\n",
    "print(scores_345_rf_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumm = np.cumsum(scores_345_rf_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig1 = plt.subplots()  \n",
    "plt.plot(a)\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot');\n",
    "fig1 = plt.subplots()  \n",
    "plt.plot(a)\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('Importance')\n",
    "plt.plot(x, rf_rfe_test['cum'], '-')\n",
    "# plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
